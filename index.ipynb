{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf0d3bf",
   "metadata": {},
   "source": [
    "# Unites States Aviation Accident Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21d421",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273e0c7",
   "metadata": {},
   "source": [
    "This is an analysis of aviation accident data from the National Transportation Safety Board (NTSB) to identify trends and patterns in civil aviation accidents and selected incidents in the United States and international waters from 1962 to 2023. The goal of this analysis is to provide insights that can inform safety measures and improve the overall safety of aviation operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff346426",
   "metadata": {},
   "source": [
    "### Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ab930",
   "metadata": {},
   "source": [
    "The aviation industry faces significant safety risks, and understanding the causes and patterns of accidents is crucial for reducing the likelihood of future incidents. By analyzing historical data on aviation accidents, we can identify common factors and trends that contribute to accidents, enabling the development of targeted safety initiatives to mitigate these risks that lead to loss of lives and financial loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57270bf5",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7012a4",
   "metadata": {},
   "source": [
    "The [dataset](https://www.kaggle.com/datasets/khsamaha/aviation-accident-database-synopses) from the National Transportation Safety Board which contains information on civil aviation accidents and selected incidents in the United States and international waters from 1962 to 2023. The data includes various features such as the probable cause of the `accident`, `location`, `date` and `details on the aircraft involved`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dd464985-aeb5-40d3-8f51-7cc7ce9db5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "13fb6179-88f5-4f43-b52e-8bc04c33205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the file into a pd data frame\n",
    "aviation = '../dsc-phase-1-project-v3/data/Aviation_Data.csv'\n",
    "df = pd.read_csv(aviation, engine = 'python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4862aa22-2ab2-4f3a-b5aa-8df396130d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contigency_dataset = df.copy()# copying original data set before cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd428c3",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a828f14d-0240-48e2-87ae-826d4f8e9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90348 entries, 0 to 90347\n",
      "Data columns (total 31 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Event.Id                88889 non-null  object \n",
      " 1   Investigation.Type      90348 non-null  object \n",
      " 2   Accident.Number         88889 non-null  object \n",
      " 3   Event.Date              88889 non-null  object \n",
      " 4   Location                88837 non-null  object \n",
      " 5   Country                 88663 non-null  object \n",
      " 6   Latitude                34382 non-null  object \n",
      " 7   Longitude               34373 non-null  object \n",
      " 8   Airport.Code            50132 non-null  object \n",
      " 9   Airport.Name            52704 non-null  object \n",
      " 10  Injury.Severity         87889 non-null  object \n",
      " 11  Aircraft.damage         85695 non-null  object \n",
      " 12  Aircraft.Category       32287 non-null  object \n",
      " 13  Registration.Number     87507 non-null  object \n",
      " 14  Make                    88826 non-null  object \n",
      " 15  Model                   88797 non-null  object \n",
      " 16  Amateur.Built           88787 non-null  object \n",
      " 17  Number.of.Engines       82805 non-null  float64\n",
      " 18  Engine.Type             81793 non-null  object \n",
      " 19  FAR.Description         32023 non-null  object \n",
      " 20  Schedule                12582 non-null  object \n",
      " 21  Purpose.of.flight       82697 non-null  object \n",
      " 22  Air.carrier             16648 non-null  object \n",
      " 23  Total.Fatal.Injuries    77488 non-null  float64\n",
      " 24  Total.Serious.Injuries  76379 non-null  float64\n",
      " 25  Total.Minor.Injuries    76956 non-null  float64\n",
      " 26  Total.Uninjured         82977 non-null  float64\n",
      " 27  Weather.Condition       84397 non-null  object \n",
      " 28  Broad.phase.of.flight   61724 non-null  object \n",
      " 29  Report.Status           82505 non-null  object \n",
      " 30  Publication.Date        73659 non-null  object \n",
      "dtypes: float64(5), object(26)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Get an Overview of the data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e47b0450-46e3-444b-ae9c-b4dbb6fc3dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90348, 31)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f9414f29-b0ab-476a-b18e-4655e2e07466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number.of.Engines</th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Total.Uninjured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82805.000000</td>\n",
       "      <td>77488.000000</td>\n",
       "      <td>76379.000000</td>\n",
       "      <td>76956.000000</td>\n",
       "      <td>82977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.146585</td>\n",
       "      <td>0.647855</td>\n",
       "      <td>0.279881</td>\n",
       "      <td>0.357061</td>\n",
       "      <td>5.325440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.446510</td>\n",
       "      <td>5.485960</td>\n",
       "      <td>1.544084</td>\n",
       "      <td>2.235625</td>\n",
       "      <td>27.913634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number.of.Engines  Total.Fatal.Injuries  Total.Serious.Injuries  \\\n",
       "count       82805.000000          77488.000000            76379.000000   \n",
       "mean            1.146585              0.647855                0.279881   \n",
       "std             0.446510              5.485960                1.544084   \n",
       "min             0.000000              0.000000                0.000000   \n",
       "25%             1.000000              0.000000                0.000000   \n",
       "50%             1.000000              0.000000                0.000000   \n",
       "75%             1.000000              0.000000                0.000000   \n",
       "max             8.000000            349.000000              161.000000   \n",
       "\n",
       "       Total.Minor.Injuries  Total.Uninjured  \n",
       "count          76956.000000     82977.000000  \n",
       "mean               0.357061         5.325440  \n",
       "std                2.235625        27.913634  \n",
       "min                0.000000         0.000000  \n",
       "25%                0.000000         0.000000  \n",
       "50%                0.000000         1.000000  \n",
       "75%                0.000000         2.000000  \n",
       "max              380.000000       699.000000  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "befd9d20-7c42-429e-a469-f0036fbe8164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event.Id                   1459\n",
       "Investigation.Type            0\n",
       "Accident.Number            1459\n",
       "Event.Date                 1459\n",
       "Location                   1511\n",
       "Country                    1685\n",
       "Latitude                  55966\n",
       "Longitude                 55975\n",
       "Airport.Code              40216\n",
       "Airport.Name              37644\n",
       "Injury.Severity            2459\n",
       "Aircraft.damage            4653\n",
       "Aircraft.Category         58061\n",
       "Registration.Number        2841\n",
       "Make                       1522\n",
       "Model                      1551\n",
       "Amateur.Built              1561\n",
       "Number.of.Engines          7543\n",
       "Engine.Type                8555\n",
       "FAR.Description           58325\n",
       "Schedule                  77766\n",
       "Purpose.of.flight          7651\n",
       "Air.carrier               73700\n",
       "Total.Fatal.Injuries      12860\n",
       "Total.Serious.Injuries    13969\n",
       "Total.Minor.Injuries      13392\n",
       "Total.Uninjured            7371\n",
       "Weather.Condition          5951\n",
       "Broad.phase.of.flight     28624\n",
       "Report.Status              7843\n",
       "Publication.Date          16689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identifying null values\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1e1e94e9-926c-472b-89f9-dc944afbdca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1390"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicates \n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a23b7-7144-4ac6-9eab-5f2e123746f0",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "485f1731-dc15-4fa3-beff-7016f83aa6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicated items in a column\n",
    "df = df.drop_duplicates(subset=['Accident.Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "46b3ea11-1483-48b0-ae29-60f67bc2aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unecessary Columns\n",
    "\n",
    "df.drop(columns = ['Latitude','Longitude','FAR.Description','Investigation.Type','Airport.Code',\n",
    "'Amateur.Built','Engine.Type','Schedule'],inplace = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "06270f4a-bfe5-4513-8aba-5302a1ece262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where 'Country' is not 'United States' and modify the original DataFrame\n",
    "\n",
    "df = df[df['Country'] == 'United States']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a04b46be-560b-4eb9-a16d-106710c0a01e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda03\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert 'Year' column to datetime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda03\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda03\\envs\\learn-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Convert 'Event.Date' column to Year\n",
    "df['Year'] = pd.to_datetime(df['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9f3ca-1606-4108-9393-b96d91abe1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove '.' and capitalize the next letter in column names\n",
    "\n",
    "df = df.rename(columns={col: col.replace('.', ' ').replace(col[col.find('.')+1], col[col.find('.')+1].upper()) for col in df.columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460987d-91c7-4b71-ba74-9826e20bfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb3f54-080f-4c84-8685-2f79be8aeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3d622-afbb-48cd-8281-a08461c65517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows with at least 18 non-null values\n",
    "df = df.dropna(thresh=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e9c07-f6a2-446f-811e-8fa23db64568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3adbf28-5282-443c-9c1d-fd793fd429e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final analysis on cleaned data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8bf88-7275-4d57-87eb-1342fca52795",
   "metadata": {},
   "source": [
    "### Summary of Statistics\n",
    "\n",
    "Here are the key insights from the final analysis on the cleaned data:\n",
    "\n",
    "The distinct column(unique identifier) in this dataframe is the `Event Id`\n",
    "\n",
    "The dataset now contains `80,357` rows after removing duplicates, incomplete cases, and other cleaning steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33d724-1ec5-47e4-b68b-a63f4438c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data to csv(for Tableau visualization later)\n",
    "df.to_csv('cleaned_aviation.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0239d2-5619-4ea6-bb91-6b61f2690fdd",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a685-3063-4e31-984f-eeaf303563f9",
   "metadata": {},
   "source": [
    "## Accident Trends by Year\n",
    "This can help identify if accidents are increasing, decreasing, or staying constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80945b-776e-41c8-aa3d-91a41ac4879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of accidents for each year\n",
    "df_year = df.groupby('Year').size().reset_index(name='Number of accidents')\n",
    "\n",
    "# Sort by year\n",
    "df_year = df_year.sort_values('Year')\n",
    "# Create line plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='Year', y='Number of accidents', data=df_year)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Accident Trends by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Accidents')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76404472",
   "metadata": {},
   "source": [
    "The GitHub repository is the cloud-hosted directory containing all of your project files as well as their version history.\n",
    "\n",
    "This repository link will be the project link that you include on your resume, LinkedIn, etc. for prospective employers to view your work. Note that we typically recommend that 3 links are highlighted (out of 5 projects) so don't stress too much about getting this one to be perfect! There will also be time after graduation for cosmetic touch-ups.\n",
    "\n",
    "A professional GitHub repository has:\n",
    "\n",
    "1. `README.md`\n",
    "    * A file called `README.md` at the root of the repository directory, written in Markdown; this is what is rendered when someone visits the link to your repository in the browser\n",
    "    * This file contains these sections:\n",
    "       * Overview\n",
    "       * Business Understanding\n",
    "          * Include stakeholder and key business questions\n",
    "       * Data Understanding and Analysis\n",
    "          * Source of data\n",
    "          * Description of data\n",
    "          * Three visualizations (the same visualizations presented in the slides and notebook)\n",
    "       * Conclusion\n",
    "          * Summary of conclusions including three relevant findings\n",
    "2. Commit history\n",
    "   * Progression of updates throughout the project time period, not just immediately before the deadline\n",
    "   * Clear commit messages\n",
    "   * Commits from all team members (if a group project)\n",
    "3. Organization\n",
    "   * Clear folder structure\n",
    "   * Clear names of files and folders\n",
    "   * Easily-located notebook and presentation linked in the README\n",
    "4. Notebook(s)\n",
    "   * Clearly-indicated final notebook that runs without errors\n",
    "   * Exploratory/working notebooks (can contain errors, redundant code, etc.) from all team members (if a group project)\n",
    "5. `.gitignore`\n",
    "   * A file called `.gitignore` at the root of the repository directory instructs Git to ignore large, unnecessary, or private files\n",
    "     * Because it starts with a `.`, you will need to type `ls -a` in the terminal in order to see that it is there\n",
    "   * GitHub maintains a [Python .gitignore](https://github.com/github/gitignore/blob/master/Python.gitignore) that may be a useful starting point for your version of this file\n",
    "   * To tell Git to ignore more files, just add a new line to `.gitignore` for each new file name\n",
    "     * Consider adding `.DS_Store` if you are using a Mac computer, as well as project-specific file names\n",
    "     * If you are running into an error message because you forgot to add something to `.gitignore` and it is too large to be pushed to GitHub [this blog post](https://medium.com/analytics-vidhya/tutorial-removing-large-files-from-git-78dbf4cf83a?sk=c3763d466c7f2528008c3777192dfb95)(friend link) should help you address this\n",
    "\n",
    "You wil submit a link to the GitHub repository on Canvas.\n",
    "\n",
    "See the [Grading](#grading) section for further explanation of how the GitHub repository will be graded.\n",
    "\n",
    "For further reading on creating professional notebooks and `README`s, check out [this reading](https://github.com/learn-co-curriculum/dsc-repo-readability-v2-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd15d88",
   "metadata": {},
   "source": [
    "### Interactive Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136adf8e",
   "metadata": {},
   "source": [
    "The interactive dashboard is a collection of views that allows the viewer to change the views to understand different features in the data. This dashboard will be linked within your GitHub repository README.md file so that users can explore your analysis. Make sure you follow visual best practices that you have learned in this course. Below is an example of what you could produce for this assignment.\n",
    "![tableau dashboard for aviation accidents](https://raw.githubusercontent.com/learn-co-curriculum/dsc-phase-1-project-v3/master/example_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0b36b",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbcebc",
   "metadata": {},
   "source": [
    "***To pass this project, you must pass each project rubric objective.*** The project rubric objectives for Phase 1 are:\n",
    "\n",
    "1. Data Communication\n",
    "2. Authoring Jupyter Notebooks\n",
    "3. Data Manipulation and Analysis with `pandas`\n",
    "4. Interactive Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28c5bc",
   "metadata": {},
   "source": [
    "### Data Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d13765",
   "metadata": {},
   "source": [
    "Communication is a key \"soft skill\". In [this survey](https://www.payscale.com/data-packages/job-skills), 46% of hiring managers said that recent college grads were missing this skill.\n",
    "\n",
    "Because \"communication\" can encompass such a wide range of contexts and skills, we will specifically focus our Phase 1 objective on Data Communication. We define Data Communication as:\n",
    "\n",
    "> Communicating basic data analysis results to diverse audiences via writing and live presentation\n",
    "\n",
    "To further define some of these terms:\n",
    "\n",
    "* By \"basic data analysis\" we mean that you are filtering, sorting, grouping, and/or aggregating the data in order to answer business questions. This project does not involve inferential statistics or machine learning, although descriptive statistics such as measures of central tendency are encouraged.\n",
    "* By \"results\" we mean your ***three visualizations and recommendations***.\n",
    "* By \"diverse audiences\" we mean that your presentation and notebook are appropriately addressing a business and data science audience, respectively.\n",
    "\n",
    "Below are the definitions of each rubric level for this objective. This information is also summarized in the rubric, which is attached to the project submission assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482a9e0",
   "metadata": {},
   "source": [
    "#### Exceeds Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0b6d8",
   "metadata": {},
   "source": [
    "Creates and describes appropriate visualizations for given business questions, where each visualization fulfills all elements of the checklist\n",
    "\n",
    "> This \"checklist\" refers to the Data Visualization checklist within the larger Phase 1 Project Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b218e",
   "metadata": {},
   "source": [
    "#### Meets Objective (Passing Bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ec39d",
   "metadata": {},
   "source": [
    "Creates and describes appropriate visualizations for given business questions\n",
    "\n",
    "> This objective can be met even if all checklist elements are not fulfilled. For example, if there is some illegible text in one of your visualizations, you can still meet this objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b8c3b",
   "metadata": {},
   "source": [
    "#### Approaching Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6408ca4",
   "metadata": {},
   "source": [
    "Creates visualizations that are not related to the business questions, or uses an inappropriate type of visualization\n",
    "\n",
    "> Even if you create very compelling visualizations, you cannot pass this objective if the visualizations are not related to the business questions\n",
    "\n",
    "> An example of an inappropriate type of visualization would be using a line graph to show the correlation between two independent variables, when a scatter plot would be more appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8f9c7",
   "metadata": {},
   "source": [
    "#### Does Not Meet Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d6c95",
   "metadata": {},
   "source": [
    "Does not submit the required number of visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fae056",
   "metadata": {},
   "source": [
    "### Authoring Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5aa56",
   "metadata": {},
   "source": [
    "According to [Kaggle's 2020 State of Data Science and Machine Learning Survey](https://www.kaggle.com/kaggle-survey-2020), 74.1% of data scientists use a Jupyter development environment, which is more than twice the percentage of the next-most-popular IDE, Visual Studio Code. Jupyter Notebooks allow for reproducible, skim-able code documents for a data science audience. Comfort and skill with authoring Jupyter Notebooks will prepare you for job interviews, take-home challenges, and on-the-job tasks as a data scientist.\n",
    "\n",
    "The key feature that distinguishes *authoring Jupyter Notebooks* from simply *writing Python code* is the fact that Markdown cells are integrated into the notebook along with the Python cells in a notebook. You have seen examples of this throughout the curriculum, but now it's time for you to practice this yourself!\n",
    "\n",
    "Below are the definitions of each rubric level for this objective. This information is also summarized in the rubric, which is attached to the project submission assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a66aa0",
   "metadata": {},
   "source": [
    "#### Exceeds Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0a5ed",
   "metadata": {},
   "source": [
    "Uses Markdown and code comments to create a well-organized, skim-able document that follows all best practices\n",
    "\n",
    "> Refer to the [repository readability reading](https://github.com/learn-co-curriculum/dsc-repo-readability-v2-2) for more tips on best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da992bca",
   "metadata": {},
   "source": [
    "#### Meets Objective (Passing Bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20984b83",
   "metadata": {},
   "source": [
    "Uses some Markdown to create an organized notebook, with an introduction at the top and a conclusion at the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0ab76",
   "metadata": {},
   "source": [
    "#### Approaching Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c094f1",
   "metadata": {},
   "source": [
    "Uses Markdown cells to organize, but either uses only headers and does not provide any explanations or justifications, or uses only plaintext without any headers to segment out sections of the notebook\n",
    "\n",
    "> Headers in Markdown are delineated with one or more `#`s at the start of the line. You should have a mixture of headers and plaintext (text where the line does not start with `#`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2caa058",
   "metadata": {},
   "source": [
    "#### Does Not Meet Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041349f8",
   "metadata": {},
   "source": [
    "Does not submit a notebook, or does not use Markdown cells at all to organize the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd316a",
   "metadata": {},
   "source": [
    "### Data Manipulation and Analysis with `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cadaef",
   "metadata": {},
   "source": [
    "`pandas` is a very popular data manipulation library, with over 2 million downloads on Anaconda (`conda install pandas`) and over 19 million downloads on PyPI (`pip install pandas`) at the time of this writing. In our own internal data, we see that the overwhelming majority of Flatiron School DS grads use `pandas` on the job in some capacity.\n",
    "\n",
    "Unlike in base Python, where the Zen of Python says \"There should be one-- and preferably only one --obvious way to do it\", there is often more than one valid way to do something in `pandas`. However there are still more efficient and less efficient ways to use it. Specifically, the best `pandas` code is *performant* and *idiomatic*.\n",
    "\n",
    "Performant `pandas` code utilizes methods and broadcasting rather than user-defined functions or `for` loops. For example, if you need to strip whitespace from a column containing string data, the best approach would be to use the [`pandas.Series.str.strip` method](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html) rather than writing your own function or writing a loop. Or if you want to multiply everything in a column by 100, the best approach would be to use broadcasting (e.g. `df[\"column_name\"] * 100`) instead of a function or loop. You can still write your own functions if needed, but only after checking that there isn't a built-in way to do it.\n",
    "\n",
    "Idiomatic `pandas` code has variable names that are meaningful words or abbreviations in English, that are related to the purpose of the variables. You can still use `df` as the name of your DataFrame if there is only one main DataFrame you are working with, but as soon as you are merging multiple DataFrames or taking a subset of a DataFrame, you should use meaningful names. For example, `df2` would not be an idiomatic name, but `movies_and_reviews` could be.\n",
    "\n",
    "We also recommend that you rename all DataFrame columns so that their meanings are more understandable, although it is fine to have acronyms. For example, `\"col1\"` would not be an idiomatic name, but `\"USD\"` could be.\n",
    "\n",
    "Below are the definitions of each rubric level for this objective. This information is also summarized in the rubric, which is attached to the project submission assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3789af2",
   "metadata": {},
   "source": [
    "#### Exceeds Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedaca9d",
   "metadata": {},
   "source": [
    "Uses `pandas` to prepare data and answer business questions in an idiomatic, performant way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f285f",
   "metadata": {},
   "source": [
    "#### Meets Objective (Passing Bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c9b18",
   "metadata": {},
   "source": [
    "Successfully uses `pandas` to prepare data in order to answer business questions\n",
    "\n",
    "> This includes projects that _occasionally_ use base Python when `pandas` methods would be more appropriate (such as using `enumerate()` on a DataFrame), or occasionally performs operations that do not appear to have any relevance to the business questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9656ca",
   "metadata": {},
   "source": [
    "#### Approaching Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b2074",
   "metadata": {},
   "source": [
    "Uses `pandas` to prepare data, but makes significant errors\n",
    "\n",
    "> Examples of significant errors include: the result presented does not actually answer the stated question, the code produces errors, the code _consistently_ uses base Python when `pandas` methods would be more appropriate, or the submitted notebook contains significant quantities of code that is unrelated to the presented analysis (such as copy/pasted code from the curriculum or StackOverflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b750b",
   "metadata": {},
   "source": [
    "#### Does Not Meet Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c11e1b",
   "metadata": {},
   "source": [
    "Unable to prepare data using `pandas`\n",
    "\n",
    "> This includes projects that successfully answer the business questions, but do not use `pandas` (e.g. use only base Python, or use some other tool like R, Tableau, or Excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49beec3",
   "metadata": {},
   "source": [
    "### Interactive Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998ec0a",
   "metadata": {},
   "source": [
    "Tableau is a powerful data analysis tool that allows data to be presented in a manner that allows it to be easily digestible with visualizations and charts to aid in the simplification of the data and its analysis. Tableau contains many customizable features and makes it easy to share in many ways. We recommend you use Tableau for your interactive data visualization now that you have experience with it.\n",
    "\n",
    "Here are the definitions of each rubric level for this objective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31fa6e",
   "metadata": {},
   "source": [
    "#### Exceeds Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14cc9d",
   "metadata": {},
   "source": [
    "Creates an easy to use dashboard to answer business questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6541d4",
   "metadata": {},
   "source": [
    "#### Meets Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86f8bc",
   "metadata": {},
   "source": [
    "Successfully creates a dashboard to answer business questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b9933",
   "metadata": {},
   "source": [
    "#### Approaching Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d08da9",
   "metadata": {},
   "source": [
    "Creates a dashboard, but it is difficult to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cdd74",
   "metadata": {},
   "source": [
    "#### Does Not Meet Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e7d90",
   "metadata": {},
   "source": [
    "Unable to create a dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ad567",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2dfa0",
   "metadata": {},
   "source": [
    "Please start by reviewing the contents of this project description. If you have any questions, please ask your instructor ASAP.\n",
    "\n",
    "Next, you will need to complete the [***Project Proposal***](#project_proposal) which must be reviewed by your instructor before you can continue with the project.\n",
    "\n",
    "Then, you will need to create a GitHub repository. There are three options:\n",
    "Interactive Data Visualization\n",
    "1. Look at the [Phase 1 Project Templates and Examples repo](https://github.com/learn-co-curriculum/dsc-project-template) and follow the directions in the MVP branch.\n",
    "2. Fork the [Phase 1 Project Repository](https://github.com/learn-co-curriculum/dsc-phase-1-project-v3), clone it locally, and work in the `student.ipynb` file. Make sure to also add and commit a PDF of your presentation to your repository with a file name of `presentation.pdf`.\n",
    "3. Create a new repository from scratch by going to [github.com/new](https://github.com/new) and copying the data files from one of the above resources into your new repository. This approach will result in the most professional-looking portfolio repository, but can be more complicated to use. So if you are getting stuck with this option, try one of the above options instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1215d",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4f7fe",
   "metadata": {},
   "source": [
    "This project will give you a valuable opportunity to develop your data science skills using real-world data. The end-of-phase projects are a critical part of the program because they give you a chance to bring together all the skills you've learned, apply them to realistic projects for a business stakeholder, practice communication skills, and get feedback to help you improve. You've got this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
